<!DOCTYPE html>
<html>
<head>
<title>Pig Sample Help</title>

</head>
<body>
	<h1>Pig Value Binning</h1>
	<h2>Description</h2>
	<p>
	<ul>
		<li>Input - Single Text or Binary Map Reduce Directory</li>
	</ul>
	</p>
	<h2>Source</h2>
	<p>The Source can be only HDFS (TEXT MAP REDUCE DIRECTORY). It has
		to be a delimiter separated value. An example is when | is the
		delimiter then the format for a line would be (X|Y|Z)</p>

	<h2>
		<a id="page1">Value Binning - Page 1</a>
	</h2>

	<h3>Binning Column</h3>

	<p>The column to use for binning. It has to be a column with a
		number type.</p>

	<h2>
		<a id="page2">Value Binning - Page 2</a>
	</h2>

	<h3>Bins</h3>

	<p>Create the number of bins you would like. The first column is
		the identifier that is actually written. The second column is the born
		in which the bin starts. The first row has always a born that is
		empty, then the rows have to be in ascendent order of their born.</p>
	<p>If the input entry has been audited, you will have access to
		generators with a name corresponding to the number of bin to generate.

	
	<p>The following example creates 3 bins '1 / 3', '2 / 3', '3 / 3',
		defined by < 5, between 5 and 10 (exclude), the rest.
	<table>
		<tr>
			<td>Name</td>
			<td>Minimum Born</td>
		</tr>
		<tr>
			<td>1 / 3</td>
			<td></td>
		</tr>
		<tr>
			<td>2 / 3</td>
			<td>5</td>
		</tr>
		<tr>
			<td>3 / 3</td>
			<td>10</td>
		</tr>
	</table>
	</p>

	<h2>
		<a id="page3">Value Binning - Page 3</a>
	</h2>

	<h3>Parallel</h3>

	Set the parallel parameter in the entire pig script. This parameter
	control the number of reducers on the pig job.

	<h3>Delimiter</h3>

	Set the delimiter of the output type. It is only relevant when using
	Text type format.

	<h3>Output Type</h3>

	Set the output type Text or Binary.

	<h3>Audit the output</h3>

	<p>If tick the default action output will be audited. This audit
		can be read by the user or used in the next actions for some actions.
	</p>
	<p>A further bin audit is also done for having the size and the
		born for each bin.</p>

	<h2>IDM Pig</h2>

	<p>
		Idm Pig is a package that contains actions that interface with <a
			target="_blank" href="http://pig.apache.org/">Pig</a> on the IDM
		platform to perform Pig actions. There are two other actions available
		from this package <a class="stopLink" id="help_pig_select"
			onclick="return false;" href="pig_select.html">Pig Select</a> , <a
			class="stopLink" id="help_pig_join" onclick="return false;"
			href="pig_join.html">Pig Join</a>, <a class="stopLink"
			id="help_pig_union" onclick="return false;" href="pig_union.html">Pig
			Union</a> and <a class="stopLink" id="help_pig_aggregator"
			onclick="return false;" href="pig_aggregator.html">Pig Aggregator</a>
	<p>On the last page of every pig action will have two interactions
		that set the output format of the pig action. These interactions are
		to set the delimiter of the file for a TEXT MAP REDUCE DIRECTORY and
		the other is to set the output type of the file to be either TEXT MAP
		REDUCE DIRECTORY or BINARY MAP-REDUCE DIRECTORY</p>
	</p>


	<p>Apache Pig is a platform for analyzing large data sets that
		consists of a high-level language for expressing data analysis
		programs, coupled with infrastructure for evaluating these programs.
		The salient property of Pig programs is that their structure is
		amenable to substantial parallelization, which in turns enables them
		to handle very large data sets. At the present time, Pig's
		infrastructure layer consists of a compiler that produces sequences of
		Map-Reduce programs, for which large-scale parallel implementations
		already exist (e.g., the Hadoop subproject). Pig's language layer
		currently consists of a textual language called Pig Latin, which has
		the following key properties:
	<ul>
		<li>Ease of programming. It is trivial to achieve parallel
			execution of simple, "embarrassingly parallel" data analysis tasks.
			Complex tasks comprised of multiple interrelated data transformations
			are explicitly encoded as data flow sequences, making them easy to
			write, understand, and maintain.</li>
		<li>Optimization opportunities. The way in which tasks are
			encoded permits the system to optimize their execution automatically,
			allowing the user to focus on semantics rather than efficiency.</li>
		<li>Extensibility. Users can create their own functions to do
			special-purpose processing.</li>
	</ul>
	</p>
	<ul>
		<li>add quick guide</li>
		<li>add interaction descriptions</li>
	</ul>
</body>
</html>
